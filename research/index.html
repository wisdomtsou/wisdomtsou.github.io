
<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>YONGPAN ZOU</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/material-design-iconic-font.min.css"><link rel="stylesheet" href="/css/app.mini.css">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="/" title="YONGPAN ZOU" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">YONGPAN ZOU</div>
					<div class="logo__tagline">Associate Professor, Shenzhen Univ.</div>
				</div>
		</a>
		<div class="logo__item logo__imagebox">
					<embed class="logo__img" src="/images/landscape_logo.svg" alt="logo">
				</div></div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">
				
				<span class="menu__text">home</span>
				
			</a>
		</li>
		<li class="menu__item menu__item--active">
			<a class="menu__link" href="/research/">
				
				<span class="menu__text">research</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/publication/">
				
				<span class="menu__text">publication</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/grant/">
				
				<span class="menu__text">grant</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/teaching/">
				
				<span class="menu__text">teaching</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/award/">
				
				<span class="menu__text">award</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/service/">
				
				<span class="menu__text">service</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/group/">
				
				<span class="menu__text">group</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/misc/">
				
				<span class="menu__text">misc</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title"></h1>
			
		</header>
		
		
		<div class="content post__content clearfix">
			<div class="flex-container">
<div class="flex-item-left">
  <style>
      .video {
        width: 400px;
        height: 200px;
      }
  </style>
  
  
  <iframe src="https://www.youtube.com/embed/seJfy4a6vbU" frameborder="no" scrolling="yes" allowfullscreen="allowfullscreen" high_quality="1" framespacing="1" class="video" >
  </iframe>

</div>
<div class="flex-item-right">
<p><strong><font color=#CE4034 size=4>[Acoustic sensing; Gesture]</font></strong> Recently, wearable devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their tiny sizes bring about new challenges to human-device interaction such as texts input. Although some novel methods have been put forward, they possess different defects and are not applicable to deal with the problem. As a result, we propose an acoustic-based texts-entry system, i.e., EchoWrite, by which texts can be entered with a finger writing in the air without wearing any additional device.
<br>
[<a href="https://yongpanzou.github.io/data/SilentSign.pdf">Paper</a>][<a href="https://yongpanzou.github.io/data/EchoWriteSlides.pdf">Slides</a>][<a href="https://yongpanzou.github.io/data/tagFreebib.txt">BibTex</a>]</p>
</div>
</div>
<div class="flex-container">
<div class="flex-item-left">
  <style>
      .video {
        width: 400px;
        height: 200px;
      }
  </style>
  
  
  <iframe src="https://www.youtube.com/embed/x6IL7M3EhAk" frameborder="no" scrolling="yes" allowfullscreen="allowfullscreen" high_quality="1" framespacing="1" class="video" >
  </iframe>

</div>
<div class="flex-item-right">
<p><strong><font color=#CE4034 size=4>[Acoustic sensing; Authentication]</font></strong> User authentication on smart devices is indispensable to keep data privacy and security. However, conventional authentication methods are not applicable for wearables due to constraints of size and hardware, which makes present wearable devices lack convenient, secure,  and low-cost authentication schemes. As a result, our team has conduct research on this topic and have proposed several novel authentication methods based on ubiquitous acoustic sensors. One of our work is making use of acoustic signals caused by dental occlusion as biometric features to identify different users as shown in demo.
<br>
[<a href="https://yongpanzou.github.io/data/SilentSign.pdf">Paper</a>][<a href="https://yongpanzou.github.io/data/EchoWriteSlides.pdf">Slides</a>][<a href="https://yongpanzou.github.io/data/tagFreebib.txt">BibTex</a>]</p>
</div>
</div>
<div class="flex-container">
<div class="flex-item-left">
  <style>
      .video {
        width: 400px;
        height: 200px;
      }
  </style>
  
  
  <iframe src="https://www.youtube.com/embed/FsRyPvlI2ks" frameborder="no" scrolling="yes" allowfullscreen="allowfullscreen" high_quality="1" framespacing="1" class="video" >
  </iframe>

</div>
<div class="flex-item-right">
<p><strong><font color=#CE4034 size=4>[Acoustic sensing; Authentication]</font></strong> With the rising popularity of smart earphones recently, they open up a new world for users to enjoy music individually, but also bring about privacy concerns at the same time. Existing few research works  share shortcomings of intrusiveness to users, high power consumption, and purely focusing on authentication. Instead, in this paper, we propose a passive sensing system called EarID with low-cost customized earphones which attains user authentication and identification at once. It makes use of a embedded microphone to sense body sounds spread out through ear canals and extract ‘fingerprints’ as a novel biometric feature.
<br>
[<a href="https://yongpanzou.github.io/data/SilentSign.pdf">Paper</a>][<a href="https://yongpanzou.github.io/data/EchoWriteSlides.pdf">Slides</a>][<a href="https://yongpanzou.github.io/data/tagFreebib.txt">BibTex</a>]</p>
</div>
</div>
<div class="flex-container">
<div class="flex-item-left">
  <style>
      .video {
        width: 400px;
        height: 200px;
      }
  </style>
  
  
  <iframe src="https://www.youtube.com/embed/PNFin8RsHYg" frameborder="no" scrolling="yes" allowfullscreen="allowfullscreen" high_quality="1" framespacing="1" class="video" >
  </iframe>

</div>
<div class="flex-item-right">
<p><strong><font color=#CE4034 size=4>[Activity recognition; IMU]</font></strong> Strength training is becoming increasingly popular among all age groups, as it helps participants increase muscle strength, improve body flexibility, reduce health risks and reshape physical forms. However, strength training imposes strict regulations on gestures and requires professional instruction in real time for the sake of body-building efficiency and safety. We propose a novel low-cost system named iCoach, to provide real-time monitoring and coaching service for strength training participants. With this device, we can recognize various training programs, detect non-standard behaviors while exercising, and assess exercising qualities of a user.
<br>
[<a href="https://yongpanzou.github.io/data/SilentSign.pdf">Paper</a>][<a href="https://yongpanzou.github.io/data/EchoWriteSlides.pdf">Slides</a>][<a href="https://yongpanzou.github.io/data/tagFreebib.txt">BibTex</a>]</p>
</div>
</div>
<div class="flex-container">
<div class="flex-item-left">
  <style>
      .video {
        width: 400px;
        height: 200px;
      }
  </style>
  
  
  <iframe src="https://www.youtube.com/embed/KPJ46Cod28k" frameborder="no" scrolling="yes" allowfullscreen="allowfullscreen" high_quality="1" framespacing="1" class="video" >
  </iframe>

</div>
<div class="flex-item-right">
<p><strong><font color=#CE4034 size=4>[Activity recognition; IMU]</font></strong> The increasing popularity of earable devices stimulates great academic interest to design novel head gesture-based
interaction technologies. But existing works simply consider it as a singular activity recognition problem. This is not in line with practice since users may have different body movements such as walking and jogging along with head gestures. We propose a method to recognize composite head-body activities with a single IMU sensor. The key idea is to make use of the inter-correlation of different activities and design a multi-task learning network to extract shared and specific representations.
<br>
[<a href="https://yongpanzou.github.io/data/SilentSign.pdf">Paper</a>][<a href="https://yongpanzou.github.io/data/EchoWriteSlides.pdf">Slides</a>][<a href="https://yongpanzou.github.io/data/tagFreebib.txt">BibTex</a>]</p>
</div>
</div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2022 YONGPAN ZOU.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>